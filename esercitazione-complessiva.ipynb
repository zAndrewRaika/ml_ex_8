{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"6a5d8681","cell_type":"markdown","source":"# **Machine Learning Project**","metadata":{}},{"id":"9d9be223","cell_type":"markdown","source":"In questa esercitazione metteremo assieme tutte le nozioni apprese dall'inizio del corso per risolvere un task specifico di machine learning.","metadata":{}},{"id":"cd9126f8","cell_type":"markdown","source":"### **Task: Semi-supervised classification**\n\nIl task che vogliamo risolvere è un task di classificazione, caratterizzato però dal fatto che solo una piccola parte dei dati che disponiamo possiede le annotazioni (label). Questa condizione è nota come `Semi-supervised learning`. \n\n### **Dataset**\n\nIl dataset che utilizzeremo sarà Fashion-MNIST, che contiene immagini di articoli di Zalando, composto da un training set di 60.000 campioni e test set con 10.000 campioni. Ogni campione è in scala di grigi e ha risoluzione 28x28. Il dataset è composto da 10 classi.\n","metadata":{}},{"id":"6c1b2838","cell_type":"markdown","source":"## **Pseudo-label**","metadata":{}},{"id":"4726ca22","cell_type":"markdown","source":"Lo **pseudo-labeling** è una tecnica utilizzata nell'ambito del *semi-supervised learning*. L'idea di base è quella di generare etichette \"artificiali\" (pseudo-etichette) per i dati non etichettati (unlabeled, \"U\"), in modo da utilizzarle durante il training del modello. Per generare queste etichette ci sono diverse strategie: nel contesto di questa esercitazione utilizzeremo un algoritmo di clustering (k-means).\n\nEcco i passaggi generali del processo di pseudo-labeling:\n\n1.  **Addestramento Iniziale**: Si addestra un algortimo di clustering sul set non etichettato (U) utilizzando un numero di cluster pari al numero di classi.\n2.  **Predizione su Dati Etichettati**: Utilizziamo l'algortimo addestrato al punto 1 per clusterizzare i dati etichettati (L), assegnandoli quindi ai cluster che abbiamo trovato durante l' addestramento iniziale.\n3.  **Mappare i cluster alle etichette**: Creiamo un mapping tra i cluster e le etichette, in modo da capire quale etichetta corrisponde allo specifico cluster. Per fare ciò assegniamo ad ogni cluster la vera label più frequente assegnata a quel cluster, sfruttando la funzione `mode`:\n\n```Python\nfrom scipy.stats import mode\nimport numpy as np\n\netichette_nel_cluster = np.array([0, 1, 1, 2, 1, 0, 1])\n\nrisultato_mode = mode(etichette_nel_cluster)\n\nprint(f\"Oggetto ModeResult: {risultato_mode}\") # Output: ModeResul(mode=1, count=4)\nprint(f\"Etichetta più frequente (moda): {risultato_mode.mode}\") # Output: (moda): 1\n\n# etichetta più frequente come singolo numero:\netichetta_predominante = risultato_mode.mode\nprint(f\"Etichetta predominante per questo cluster: {etichetta_predominante}\") # Output: 1\n```\n\n4.  **Estrazione pseudo-label**: Alla fine, la classe più presente in un cluster diventa l' etichetta scelta per tutti i campioni assegnati a quel cluster. \n\n\n**Vantaggi**:\n*   Permette di sfruttare la grande quantità di dati non etichettati, che altrimenti andrebbero sprecati.\n*   Può migliorare significativamente le prestazioni del modello rispetto all'addestramento con i soli dati etichettati, specialmente quando questi ultimi sono scarsi.","metadata":{}},{"id":"748cbb1a","cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cluster import KMeans\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom scipy.stats import mode # For majority voting\nfrom sklearn.neural_network import MLPClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:06:09.091203Z","iopub.execute_input":"2025-05-29T16:06:09.091577Z","iopub.status.idle":"2025-05-29T16:06:09.098100Z","shell.execute_reply.started":"2025-05-29T16:06:09.091550Z","shell.execute_reply":"2025-05-29T16:06:09.097007Z"}},"outputs":[],"execution_count":2},{"id":"671e368d","cell_type":"code","source":"# Nomi delle classi per Fashion-MNIST\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:06:12.433485Z","iopub.execute_input":"2025-05-29T16:06:12.433829Z","iopub.status.idle":"2025-05-29T16:06:12.439266Z","shell.execute_reply.started":"2025-05-29T16:06:12.433803Z","shell.execute_reply":"2025-05-29T16:06:12.438161Z"}},"outputs":[],"execution_count":3},{"id":"1a7b5d18","cell_type":"markdown","source":"### `load_and_preprocess_data()`\n\nIn questa funzione dovrete:\n\n* Scaricare il dataset.\n* Riordinare casualmente i dati.\n* Effettuare reshape.\n* Scalare i valori dei pixel all' intervallo [0,1].\n* Ridurre il numero di campioni a 10.000 per il train e 1.000 per il test.\n\nLa funzione dovrà ritornare nel seguente ordine:\n\n1. Il training set ridotto.\n2. Le etichette di train ridotte.\n3. Il test set ridotto.\n4. Le etichette di test ridotte.","metadata":{}},{"id":"8885ad81","cell_type":"code","source":"def load_and_preprocess_data():\n    \"\"\"Carica e pre-processa il dataset Fashion-MNIST.\"\"\"\n    np.random.seed(0)\n\n    (x_train, y_train), (x_test,y_test) = fashion_mnist.load_data()\n\n    indices = np.arange(x_train.shape[0]) \n    np.random.shuffle(indices)            \n    x_train = x_train[indices]            \n    y_train = y_train[indices]\n    \n    indices = np.arange(x_test.shape[0]) \n    np.random.shuffle(indices) \n    x_test = x_test[indices]\n    y_test = y_test[indices]\n\n    x_train = x_train.reshape(x_train.shape[0], -1)\n    x_test = x_test.reshape(x_test.shape[0], -1)\n\n    x_train = x_train.astype('float32') / 255.0\n    x_test = x_test.astype('float32') / 255.0\n\n    x_train_reduced = x_train[:10000]\n    x_test_reduced = x_test[:1000]\n    y_train_reduced = y_train[:10000]\n    y_test_reduced = y_test[:1000]\n\n    print(\"Dimensioni training: \", x_train_reduced.shape ,y_train_reduced.shape)\n    print(\"Dimensioni test: \", x_test_reduced.shape, y_train_reduced.shape)\n    \n    return x_train_reduced,y_train_reduced,x_test_reduced,y_test_reduced","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:06:22.667361Z","iopub.execute_input":"2025-05-29T16:06:22.667775Z","iopub.status.idle":"2025-05-29T16:06:22.676421Z","shell.execute_reply.started":"2025-05-29T16:06:22.667746Z","shell.execute_reply":"2025-05-29T16:06:22.675320Z"}},"outputs":[],"execution_count":5},{"id":"7e4f4f2c","cell_type":"markdown","source":"### `apply_pca_and_scale`\n\nIn questa funzione dovrete:\n\n* Scalare il training set e il test set.\n* Applicare PCA con un numero di componenti specificato come parametro della funzione (o, equivalentemente, con una frazione desiderata della varianza espressa).\n* Stampare il numero di componenti.\n* Stampare la varianza espressa.\n\nLa funzione dovrà ritornare nel seguente ordine:\n\n1. Il training set trasformato con PCA.\n2. Il test set trasformato con PCA.","metadata":{}},{"id":"cf661359","cell_type":"code","source":"def apply_pca_and_scale(x_train, x_test, n_components):\n    \"\"\"Applica StandardScaler e PCA.\"\"\"\n\n    standard_scaler = StandardScaler()\n    x_train_std = standard_scaler.fit_transform(x_train)\n    x_test_std = standard_scaler.transform(x_test)\n    \n    pca = PCA(n_components=n_components)\n    x_train_pca = pca.fit_transform(x_train_std)\n    x_test_pca = pca.transform(x_test_std)\n    \n    # Informazioni diagnostiche\n    print(f\"\\nPCA applicata con {n_components} componenti\")\n    print(f\"Varianza totale conservata: {np.sum(pca.explained_variance_ratio_):.3f}\")\n    print(f\"Shape risultanti - Train: {x_train_pca.shape}, Test: {x_test_pca.shape}\")\n    \n    return x_train_pca, x_test_pca","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:06:41.947099Z","iopub.execute_input":"2025-05-29T16:06:41.947430Z","iopub.status.idle":"2025-05-29T16:06:41.954357Z","shell.execute_reply.started":"2025-05-29T16:06:41.947404Z","shell.execute_reply":"2025-05-29T16:06:41.953212Z"}},"outputs":[],"execution_count":8},{"id":"c19d6064","cell_type":"markdown","source":"### `create_semi_supervised_split`\n\nIn questa funzione dovrete:\n\n* Splittare il training set in due insiemi, etichettato (L) e non etichettato (U) utilizzando  `train_test_split` con:\n\n`test_size`=`(1.0 - labeled_fraction)`\n\n* Stampare la shape del set etichettato.\n* Stampare la shape del set non etichettato.\n\nLa funzione deve ritornare nell seguente ordine:\n\n1. Il set etichettato.\n2. Le etichette del set etichettato.\n3. Il set non etichettato.\n4. Le etichette del set non etichettato. **N.B.** Queste etichette verranno utilizzate **SOLO** per valutare le pseudo-labels, non per l'addestramento.\n","metadata":{}},{"id":"8c868c74","cell_type":"code","source":"def create_semi_supervised_split(x_train_pca, y_train, labeled_fraction):\n    \"\"\"Crea gli insiemi etichettato (L) e non etichettato (U).\"\"\"\n    L, U, y_l, y_u = train_test_split(x_train_pca, y_train, test_size=(1.0 - labeled_fraction), stratify=y_train, random_state = 42)\n    print(L.shape, U.shape)\n    \n    return L, y_l, U, y_u","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:06:45.642533Z","iopub.execute_input":"2025-05-29T16:06:45.642832Z","iopub.status.idle":"2025-05-29T16:06:45.649222Z","shell.execute_reply.started":"2025-05-29T16:06:45.642812Z","shell.execute_reply":"2025-05-29T16:06:45.647835Z"}},"outputs":[],"execution_count":9},{"id":"4052846d","cell_type":"markdown","source":"### `get_pseudo_labels`\n\nIn questa funzione dovrete:\n\n* Istanziare un algoritmo di clustering (ad esempio, k-means).\n* Addestrare e predire i clustering sul set non etichettato.\n* Predire i clustering del set etichettato.\n* Mappare i cluster ad un etichetta, utilizzando per ogni cluster l'etichetta più presente, estraibile utilizzando la funzione `mode` presentata sopra.\n* Generare un array `pseudo_labels` assegnando a ogni campione del set non etichettato l'etichetta corrispondente al cluster a cui è stato assegnato.\n\nLa funzione deve ritornare:\n\n1. L' array `pseudo_labels`.","metadata":{}},{"id":"d6560820","cell_type":"code","source":"def get_pseudo_labels(x_unlabeled_pca, x_labeled_pca, y_labeled, n_clusters):\n\n    # 1. Istanziare algoritmo di clustering\n    clustering_model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n\n    # 2. Allenare il modello di clustering con i dati non etichettati e salvare le assegnazioni ai cluster\n    clustering_model.fit(x_unlabeled_pca)\n    cluster_assignments_unlabeled = clustering_model.labels_\n\n    # 3. Calcolare l'assegnamento dei dati etichettati ai cluster\n    cluster_assignments_labeled = clustering_model.predict(x_labeled_pca)\n\n    # 4. Mappiamo i cluster alle label vere più frequenti\n    cluster_to_true_label_map = {}\n    for k_idx in range(n_clusters):\n        # 4.1 Troviamo per ogni cluster le etichette vere dei campioni che vi appartengono.\n        mask = (cluster_assignments_labeled == k_idx)\n        labels_in_cluster = y_labeled[mask]\n\n        # 4.2 Troviamo l'etichetta più frequente per quel cluster.\n        if len(labels_in_cluster) > 0:\n            most_common_label = mode(labels_in_cluster, keepdims=True).mode[0]\n        else:\n            most_common_label = np.nan\n\n        # 4.3 Salviamo l'etichetta più frequente per quel cluster in cluster_to_true_label_map.\n        cluster_to_true_label_map[k_idx] = most_common_label\n\n    pseudo_labels_list = []\n    for c_assign in cluster_assignments_unlabeled:\n        if c_assign in cluster_to_true_label_map:\n            # Assegnamo l'etichetta più frequente trovata per quel cluster\n            pseudo_labels_list.append(cluster_to_true_label_map[c_assign])\n        else:\n            # Se il cluster non ha una mappatura, possiamo assegnare un'etichetta di default o ignorarlo\n            pseudo_labels_list.append(np.nan)\n    \n    # 5. Convertiamo la lista in un array numpy\n    pseudo_labels = np.array(pseudo_labels_list)\n    \n    return pseudo_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:06:48.588287Z","iopub.execute_input":"2025-05-29T16:06:48.588650Z","iopub.status.idle":"2025-05-29T16:06:48.597141Z","shell.execute_reply.started":"2025-05-29T16:06:48.588626Z","shell.execute_reply":"2025-05-29T16:06:48.596063Z"}},"outputs":[],"execution_count":10},{"id":"316409a5","cell_type":"markdown","source":"### `train_and_evaluate_classifier`\n\nIn questa funzione dovrete:\n\n* Rimuovere eventuali campioni con etichette NaN (potrebbero provenire da pseudo labels non mappate).\n* Istanziare il modello utilizzando `model_class` come oggetto e `classifier_args` come argomenti. Esempio:\n\n```Python\nmodel_class = MLPClassifier\nclassifier_args = {'max_iter': 200, 'hidden_layer_sizes': (100, 50)}\nmodel = model_class(**classifier_args)\n\n# Equivalente a:\nmodel = MLPClassifier(max_iter=200, hidden_layer_sizes=(100, 50))\n\n```\n\n* Allenare il modello sul training set a cui sono stati rimossi i campioni con etichette NaN.\n* Calcolare l' accuracy.\n* Stampare il `title`, che consiste nel titolo dell' esperimento eseguito. Questo perchè tale funzione verrà riutilizzata diverse volte per più set di dati. Un titolo ci permetterà di identificare quali risultati stiamo producendo.\n* Stampare l' accuracy.\n* Stampare il classification report.\n\nLa funzione deve ritornare:\n\n1. Il modello.\n","metadata":{}},{"id":"d4d5b673","cell_type":"code","source":"def train_and_evaluate_classifier(model_class, classifier_args, x_train, y_train, x_test, y_test, title, class_names_list):\n    valid_indices_train = ~np.isnan(y_train)\n    x_train = x_train[valid_indices_train]\n    y_train = y_train[valid_indices_train]\n    model = model_class(**classifier_args)\n    model.fit(x_train,y_train)\n    prediction = model.predict(x_test)\n    accuracy = accuracy_score(y_test,prediction)\n\n    print(title)\n    print(\"accuracy: \", accuracy)\n    print(\"Classification Report:\\n\", classification_report(y_test,prediction, target_names = class_names_list))\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:06:52.714247Z","iopub.execute_input":"2025-05-29T16:06:52.714600Z","iopub.status.idle":"2025-05-29T16:06:52.721341Z","shell.execute_reply.started":"2025-05-29T16:06:52.714575Z","shell.execute_reply":"2025-05-29T16:06:52.720037Z"}},"outputs":[],"execution_count":11},{"id":"3a1c37dd","cell_type":"markdown","source":"### `main`\n\nIn questa funzione dovrete:\n\n* Utilizzare la funzione `load_and_preprocess_data` per caricare e pre-processare i dati.\n* Utilizzare la funzione `apply_pca_and_scale` per applicare scaling e PCA.\n* Utilizzare la funzione `create_semi_supervised_split` per dividere il train set in set etichettato e non etichettato.\n* Utilizzare la funzione `get_pseudo_labels` per calcoalre le pseudo labels sul set non etichettato.\n* Calcolare l' accuracy delle pseudo labels, cioè confrontarle con quelle vere in modo da vedere quanto sono accurate.\n* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello solo sui dati etichettati (L).\n* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello solo sui dati non etichettati (U).\n* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello sui dati etichettati (L) più quelli non etichettati (U).\n* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello su tutto il dataset originale.","metadata":{}},{"id":"715e5f56","cell_type":"code","source":"def main(classifier_class, classifier_args, n_components_pca, labeled_fraction, n_clusters):\n    # 1. Caricamento e pre-processing dei dati\n    x_train, y_train, x_test, y_test = load_and_preprocess_data()\n    \n    # 2. Applicazione PCA e scaling\n    x_train_pca, x_test_pca = apply_pca_and_scale(x_train, x_test, n_components_pca)\n    \n    # 3. Creazione split semi-supervisionato\n    L, y_l, U, y_u = create_semi_supervised_split(x_train_pca, y_train, labeled_fraction)\n    \n    # 4. Calcolo pseudo-labels\n    pseudo_labels = get_pseudo_labels(U, L, y_l, n_clusters)\n    \n    # 5. Valutazione accuratezza pseudo-labels\n    valid_pseudo_indices = ~np.isnan(pseudo_labels)\n    pseudo_labels_valid = pseudo_labels[valid_pseudo_indices]\n    U_valid = U[valid_pseudo_indices]\n    y_u_valid = y_u[valid_pseudo_indices]\n    \n    if len(pseudo_labels_valid) > 0:\n        pseudo_accuracy = accuracy_score(y_u_valid, pseudo_labels_valid)\n        print(f\"\\nAccuracy delle pseudo-labels: {pseudo_accuracy:.3f}\")\n        print(\"Classification Report per pseudo-labels:\\n\", \n              classification_report(y_u_valid, pseudo_labels_valid, target_names=class_names))\n    else:\n        print(\"\\nAttenzione: nessuna pseudo-label valida generata\")\n    \n    # 6. Addestramento e valutazione modelli\n    print(\"\\n\" + \"=\"*50)\n    print(\"Modello addestrato solo sui dati etichettati (L)\")\n    model_L = train_and_evaluate_classifier(\n        classifier_class, classifier_args, \n        L, y_l, \n        x_test_pca, y_test,\n        \"Risultati con solo dati etichettati (L):\",\n        class_names\n    )\n    \n    print(\"\\n\" + \"=\"*50)\n    print(\"Modello addestrato solo sui dati non etichettati con pseudo-labels (U)\")\n    model_U = train_and_evaluate_classifier(\n        classifier_class, classifier_args, \n        U_valid, pseudo_labels_valid, \n        x_test_pca, y_test,\n        \"Risultati con solo dati non etichettati (U) e pseudo-labels:\",\n        class_names\n    )\n    \n    print(\"\\n\" + \"=\"*50)\n    print(\"Modello addestrato su dati etichettati (L) + non etichettati (U) con pseudo-labels\")\n    # Combiniamo L e U_valid\n    L_U_combined = np.vstack([L, U_valid])\n    L_U_labels = np.concatenate([y_l, pseudo_labels_valid])\n    model_LU = train_and_evaluate_classifier(\n        classifier_class, classifier_args, \n        L_U_combined, L_U_labels, \n        x_test_pca, y_test,\n        \"Risultati con dati etichettati (L) + non etichettati (U) e pseudo-labels:\",\n        class_names\n    )\n    \n    print(\"\\n\" + \"=\"*50)\n    print(\"Modello addestrato su tutto il dataset originale\")\n    model_full = train_and_evaluate_classifier(\n        classifier_class, classifier_args, \n        x_train_pca, y_train, \n        x_test_pca, y_test,\n        \"Risultati con tutto il dataset originale:\",\n        class_names\n    )\n    \n    return {\n        'model_L': model_L,\n        'model_U': model_U,\n        'model_LU': model_LU,\n        'model_full': model_full,\n        'pseudo_accuracy': pseudo_accuracy if len(pseudo_labels_valid) > 0 else None\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T16:12:19.176294Z","iopub.execute_input":"2025-05-29T16:12:19.176674Z","iopub.status.idle":"2025-05-29T16:12:19.187036Z","shell.execute_reply.started":"2025-05-29T16:12:19.176646Z","shell.execute_reply":"2025-05-29T16:12:19.185774Z"}},"outputs":[],"execution_count":13},{"id":"59e4e39c","cell_type":"markdown","source":"### **Utilizzare la funzione `main`**\n\nSpecifichiamo adesso un set di parametri richiesti dalla funzione main e utilizziamola. Nello specifico la funzione main ha bisogno di:\n\n* `classifier_class`: quale classificatore utilizzare, ad esempio `'MLPClassifier'`, `'LogisticRegression'` o altri visti in precedenza.\n* `classifier_args`: un dizionario contenente i parametri del classificatore scelto, ad esempio un `MLPClassifier` necessiterà del parametro `hidden_layer_sizes`. Dipendentemente da quale classificatore scegliete dovrete creare il dizionario.\n* `n_components_pca`: numero di componenti di PCA che vogliamo utilizzare. Se specifichiamo un valore compreso in [0, 1] questo verrà considerato come la percentuale di varianza che vogliamo mentenere.\n* `labeled_fraction`: percentuale di dati da usare come insieme etichettato. Si consiglia il valore 0.002 corrispondente allo 0.2%, cioè 16 immagini su 8000.\n* `n_clusters`: numero di cluster da utilizzare, nel nostro caso vogliamo che ci sia un cluster per ogni classe, quindi 10.\n\nInfine utilizziamo la funzione main.","metadata":{}},{"id":"beadf602","cell_type":"code","source":"# Parametri\nCLASSIFIER_CLASS = MLPClassifier  # Modello da usare, ad esempio LogisticRegression o SVC\nCLASSIFIER_ARGS = {\n    'max_iter': 20,\n    'hidden_layer_sizes': (200,200)  # Aumenta il numero di iterazioni per la convergenza\n}\nN_COMPONENTS_PCA = 0.95  # Mantiene il 95% della varianza spiegata, o un numero fisso es. 50\nLABELED_FRACTION = 0.002   # Frazione di dati da usare come insieme etichettato L\nN_CLUSTERS = 10          # Fashion-MNIST ha 10 classi","metadata":{"trusted":true},"outputs":[],"execution_count":14},{"id":"d9d2cb39","cell_type":"code","source":"main(\n    CLASSIFIER_CLASS,\n    CLASSIFIER_ARGS,\n    N_COMPONENTS_PCA,\n    LABELED_FRACTION,\n    N_CLUSTERS\n)","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDimensioni training:  (10000, 784) (10000,)\nDimensioni test:  (1000, 784) (10000,)\n\nPCA applicata con 0.95 componenti\nVarianza totale conservata: 0.950\nShape risultanti - Train: (10000, 245), Test: (1000, 245)\n(20, 245) (9980, 245)\n\nAccuracy delle pseudo-labels: 0.461\nClassification Report per pseudo-labels:\n               precision    recall  f1-score   support\n\n T-shirt/top       0.46      0.60      0.52       964\n     Trouser       0.59      0.90      0.71       999\n    Pullover       0.38      0.62      0.47      1005\n       Dress       0.10      0.13      0.11      1022\n        Coat       0.00      0.00      0.00      1007\n      Sandal       0.38      0.89      0.53      1019\n       Shirt       0.00      0.00      0.00       961\n     Sneaker       0.00      0.00      0.00       957\n         Bag       0.95      0.55      0.70       613\n  Ankle boot       0.82      0.92      0.87      1023\n\n    accuracy                           0.46      9570\n   macro avg       0.37      0.46      0.39      9570\nweighted avg       0.35      0.46      0.38      9570\n\n\n==================================================\nModello addestrato solo sui dati etichettati (L)\nRisultati con solo dati etichettati (L):\naccuracy:  0.476\nClassification Report:\n               precision    recall  f1-score   support\n\n T-shirt/top       0.72      0.46      0.56        85\n     Trouser       0.72      0.81      0.76        91\n    Pullover       0.37      0.26      0.30       109\n       Dress       0.36      0.37      0.36       102\n        Coat       0.43      0.50      0.46       112\n      Sandal       0.44      0.27      0.34       104\n       Shirt       0.15      0.26      0.19        95\n     Sneaker       0.58      0.62      0.60       101\n         Bag       0.68      0.61      0.64       113\n  Ankle boot       0.64      0.64      0.64        88\n\n    accuracy                           0.48      1000\n   macro avg       0.51      0.48      0.49      1000\nweighted avg       0.50      0.48      0.48      1000\n\n\n==================================================\nModello addestrato solo sui dati non etichettati con pseudo-labels (U)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Risultati con solo dati non etichettati (U) e pseudo-labels:\naccuracy:  0.424\nClassification Report:\n               precision    recall  f1-score   support\n\n T-shirt/top       0.37      0.53      0.43        85\n     Trouser       0.61      0.91      0.73        91\n    Pullover       0.35      0.58      0.44       109\n       Dress       0.11      0.17      0.13       102\n        Coat       0.00      0.00      0.00       112\n      Sandal       0.37      0.84      0.51       104\n       Shirt       0.00      0.00      0.00        95\n     Sneaker       0.00      0.00      0.00       101\n         Bag       0.98      0.42      0.59       113\n  Ankle boot       0.64      0.92      0.75        88\n\n    accuracy                           0.42      1000\n   macro avg       0.34      0.44      0.36      1000\nweighted avg       0.34      0.42      0.35      1000\n\n\n==================================================\nModello addestrato su dati etichettati (L) + non etichettati (U) con pseudo-labels\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Risultati con dati etichettati (L) + non etichettati (U) e pseudo-labels:\naccuracy:  0.428\nClassification Report:\n               precision    recall  f1-score   support\n\n T-shirt/top       0.36      0.53      0.43        85\n     Trouser       0.60      0.91      0.72        91\n    Pullover       0.36      0.59      0.45       109\n       Dress       0.13      0.20      0.15       102\n        Coat       0.00      0.00      0.00       112\n      Sandal       0.38      0.84      0.52       104\n       Shirt       0.00      0.00      0.00        95\n     Sneaker       0.00      0.00      0.00       101\n         Bag       0.98      0.43      0.60       113\n  Ankle boot       0.66      0.91      0.77        88\n\n    accuracy                           0.43      1000\n   macro avg       0.35      0.44      0.36      1000\nweighted avg       0.35      0.43      0.36      1000\n\n\n==================================================\nModello addestrato su tutto il dataset originale\nRisultati con tutto il dataset originale:\naccuracy:  0.851\nClassification Report:\n               precision    recall  f1-score   support\n\n T-shirt/top       0.73      0.81      0.77        85\n     Trouser       0.98      0.96      0.97        91\n    Pullover       0.74      0.84      0.79       109\n       Dress       0.82      0.88      0.85       102\n        Coat       0.81      0.71      0.76       112\n      Sandal       0.97      0.93      0.95       104\n       Shirt       0.66      0.56      0.61        95\n     Sneaker       0.93      0.94      0.94       101\n         Bag       0.98      0.96      0.97       113\n  Ankle boot       0.87      0.92      0.90        88\n\n    accuracy                           0.85      1000\n   macro avg       0.85      0.85      0.85      1000\nweighted avg       0.85      0.85      0.85      1000\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'model_L': MLPClassifier(hidden_layer_sizes=(200, 200), max_iter=20),\n 'model_U': MLPClassifier(hidden_layer_sizes=(200, 200), max_iter=20),\n 'model_LU': MLPClassifier(hidden_layer_sizes=(200, 200), max_iter=20),\n 'model_full': MLPClassifier(hidden_layer_sizes=(200, 200), max_iter=20),\n 'pseudo_accuracy': 0.4607105538140021}"},"metadata":{}}],"execution_count":15}]}